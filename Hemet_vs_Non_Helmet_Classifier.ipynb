{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NxSIXfdjFw0",
        "outputId": "395f0cc0-45b3-40b6-db10-94ca43ccb8ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in GDUT-HWD-1 to coco:: 100%|██████████| 735656/735656 [00:09<00:00, 79902.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to GDUT-HWD-1 in coco:: 100%|██████████| 13507/13507 [00:05<00:00, 2480.99it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"IGG8TZyvElUMNWRoIZXf\")\n",
        "project = rf.workspace(\"gduthwd-phkwd\").project(\"gdut-hwd\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Dataset location:\", dataset.location)\n",
        "print(\"Folders inside:\")\n",
        "!ls \"{dataset.location}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeEvFkj1k32e",
        "outputId": "18ac6ca4-9535-4bda-ecc0-93d5ca8f7d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset location: /content/GDUT-HWD-1\n",
            "Folders inside:\n",
            "README.dataset.txt  README.roboflow.txt  test  train  valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_dir = dataset.location        # e.g. \"/content/GDUT-HWD-1\"\n",
        "splits = [\"train\", \"valid\"]        # we'll build train/val for classifier\n",
        "\n",
        "out_base = \"/content/helmet_cls\"   # new classification dataset root\n",
        "\n",
        "classes = [\"no_helmet\", \"helmet\"]\n",
        "\n",
        "for split in splits:\n",
        "    for c in classes:\n",
        "        os.makedirs(os.path.join(out_base, split, c), exist_ok=True)\n",
        "\n",
        "    anno_path = os.path.join(base_dir, split, \"_annotations.coco.json\")\n",
        "    print(f\"Processing {anno_path}\")\n",
        "\n",
        "    with open(anno_path, \"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    cat_id_to_name = {c[\"id\"]: c[\"name\"] for c in coco[\"categories\"]}\n",
        "    print(\"Categories:\", cat_id_to_name)\n",
        "\n",
        "    # group annotations by image\n",
        "    anns_by_img = {}\n",
        "    for ann in coco[\"annotations\"]:\n",
        "        anns_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
        "\n",
        "    img_id_to_info = {img[\"id\"]: img for img in coco[\"images\"]}\n",
        "\n",
        "    for img_id, img_info in tqdm(img_id_to_info.items()):\n",
        "        img_path = os.path.join(base_dir, split, img_info[\"file_name\"])\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        anns = anns_by_img.get(img_id, [])\n",
        "\n",
        "        head_boxes = [a for a in anns if cat_id_to_name[a[\"category_id\"]] == \"head\"]\n",
        "        helmet_boxes = [a for a in anns if cat_id_to_name[a[\"category_id\"]] == \"helmet\"]\n",
        "\n",
        "        # for each head, see if any helmet overlaps => label \"helmet\"\n",
        "        for idx, head in enumerate(head_boxes):\n",
        "            x, y, w, h = head[\"bbox\"]\n",
        "            x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)\n",
        "\n",
        "            label = \"no_helmet\"\n",
        "\n",
        "            for helmet in helmet_boxes:\n",
        "                hx, hy, hw, hh = helmet[\"bbox\"]\n",
        "                hx1, hy1, hx2, hy2 = int(hx), int(hy), int(hx + hw), int(hh + hy)\n",
        "\n",
        "                ix1, iy1 = max(x1, hx1), max(y1, hy1)\n",
        "                ix2, iy2 = min(x2, hx2), min(y2, hy2)\n",
        "\n",
        "                if ix2 > ix1 and iy2 > iy1:\n",
        "                    inter = (ix2 - ix1) * (iy2 - iy1)\n",
        "                    union = (x2 - x1) * (y2 - y1) + (hx2 - hx1) * (hy2 - hy1) - inter\n",
        "                    iou = inter / union if union > 0 else 0\n",
        "\n",
        "                    if iou > 0.1:\n",
        "                        label = \"helmet\"\n",
        "                        break\n",
        "\n",
        "            crop = img[y1:y2, x1:x2]\n",
        "            if crop.size == 0:\n",
        "                continue\n",
        "\n",
        "            out_dir = os.path.join(out_base, split, label)\n",
        "            out_name = f\"{img_id}_{idx}.jpg\"\n",
        "            cv2.imwrite(os.path.join(out_dir, out_name), crop)\n",
        "\n",
        "print(\"Done. Crops saved under:\", out_base)\n",
        "!tree -L 3 {out_base}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX0ICNP3k8Ao",
        "outputId": "2ea9b590-171a-4f62-f993-712ffeaf2c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/GDUT-HWD-1/train/_annotations.coco.json\n",
            "Categories: {0: 'helmet', 1: 'head', 2: 'helmet', 3: 'person'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12749/12749 [00:29<00:00, 437.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/GDUT-HWD-1/valid/_annotations.coco.json\n",
            "Categories: {0: 'helmet', 1: 'head', 2: 'helmet', 3: 'person'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 478.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Crops saved under: /content/helmet_cls\n",
            "/bin/bash: line 1: tree: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base = \"/content/helmet_cls\"\n",
        "for split in [\"train\", \"valid\"]:\n",
        "    print(f\"\\n=== {split} ===\")\n",
        "    for cls in os.listdir(os.path.join(base, split)):\n",
        "        cls_dir = os.path.join(base, split, cls)\n",
        "        if os.path.isdir(cls_dir):\n",
        "            count = len(os.listdir(cls_dir))\n",
        "            print(f\"{cls}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySt6D9BWlFU_",
        "outputId": "d757fc56-2fa4-431c-d87d-8ba9ae277079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== train ===\n",
            "no_helmet: 13690 images\n",
            "helmet: 402 images\n",
            "\n",
            "=== valid ===\n",
            "no_helmet: 642 images\n",
            "helmet: 10 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "base = \"/content/helmet_cls\"\n",
        "\n",
        "def downsample_class(split, cls_name, target_count):\n",
        "    cls_dir = os.path.join(base, split, cls_name)\n",
        "    all_files = [os.path.join(cls_dir, f) for f in os.listdir(cls_dir) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "\n",
        "    print(f\"{split}/{cls_name} has {len(all_files)} images, target = {target_count}\")\n",
        "\n",
        "    if len(all_files) <= target_count:\n",
        "        print(\"Nothing to downsample.\")\n",
        "        return\n",
        "\n",
        "    # keep this many\n",
        "    keep_files = set(random.sample(all_files, target_count))\n",
        "\n",
        "    # move the rest to a backup folder\n",
        "    backup_dir = os.path.join(base, f\"{split}_{cls_name}_unused\")\n",
        "    os.makedirs(backup_dir, exist_ok=True)\n",
        "\n",
        "    removed = 0\n",
        "    for f in all_files:\n",
        "        if f not in keep_files:\n",
        "            shutil.move(f, os.path.join(backup_dir, os.path.basename(f)))\n",
        "            removed += 1\n",
        "\n",
        "    print(f\"Moved {removed} images from {split}/{cls_name} to {backup_dir}\")\n",
        "\n",
        "# downsample train & valid no_helmet\n",
        "downsample_class(\"train\", \"no_helmet\", 800)\n",
        "downsample_class(\"valid\", \"no_helmet\", 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrTe24yUmtyW",
        "outputId": "57b279a9-7b61-4cfd-e6f0-cd545a9d12df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/no_helmet has 13690 images, target = 800\n",
            "Moved 12890 images from train/no_helmet to /content/helmet_cls/train_no_helmet_unused\n",
            "valid/no_helmet has 642 images, target = 100\n",
            "Moved 542 images from valid/no_helmet to /content/helmet_cls/valid_no_helmet_unused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "base = \"/content/helmet_cls\"\n",
        "\n",
        "train_helmet = os.path.join(base, \"train\", \"helmet\")\n",
        "valid_helmet = os.path.join(base, \"valid\", \"helmet\")\n",
        "\n",
        "train_files = [os.path.join(train_helmet, f) for f in os.listdir(train_helmet) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "\n",
        "print(\"Train helmet before:\", len(train_files))\n",
        "\n",
        "move_count = min(60, len(train_files) - 20)  # keep at least ~20 in train\n",
        "files_to_move = random.sample(train_files, move_count)\n",
        "\n",
        "for f in files_to_move:\n",
        "    shutil.move(f, os.path.join(valid_helmet, os.path.basename(f)))\n",
        "\n",
        "print(f\"Moved {move_count} helmet images to valid.\")\n",
        "print(\"Train helmet after:\", len(os.listdir(train_helmet)))\n",
        "print(\"Valid helmet now:\", len(os.listdir(valid_helmet)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FadwNWaVmvQ3",
        "outputId": "b72e7569-e007-4658-d84c-6b97cf044456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train helmet before: 402\n",
            "Moved 60 helmet images to valid.\n",
            "Train helmet after: 342\n",
            "Valid helmet now: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base = \"/content/helmet_cls\"\n",
        "for split in [\"train\", \"valid\"]:\n",
        "    print(f\"\\n=== {split} ===\")\n",
        "    for cls in os.listdir(os.path.join(base, split)):\n",
        "        cls_dir = os.path.join(base, split, cls)\n",
        "        if os.path.isdir(cls_dir):\n",
        "            count = len(os.listdir(cls_dir))\n",
        "            print(f\"{cls}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoBgS9NwmzbA",
        "outputId": "a6847227-2444-4e16-f63d-9c4a2916612c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== train ===\n",
            "no_helmet: 800 images\n",
            "helmet: 342 images\n",
            "\n",
            "=== valid ===\n",
            "no_helmet: 100 images\n",
            "helmet: 70 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "data_dir = \"/content/helmet_cls\"\n",
        "train_dir = f\"{data_dir}/train\"\n",
        "val_dir   = f\"{data_dir}/valid\"\n",
        "\n",
        "# 1. Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# 2. Datasets\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_dataset   = datasets.ImageFolder(val_dir, transform=transform)\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)  # should be ['helmet', 'no_helmet']\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# 3. Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 4. Model\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # helmet / no_helmet\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# 5. Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "    val_acc = 100.0 * correct / total if total > 0 else 0.0\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f} - Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "# 6. Save model + class names\n",
        "torch.save({\n",
        "    \"state_dict\": model.state_dict(),\n",
        "    \"classes\": train_dataset.classes\n",
        "}, \"/content/resnet18_helmet_binary.pth\")\n",
        "\n",
        "print(\"Saved model to /content/resnet18_helmet_binary.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywYx5tTnlyrM",
        "outputId": "fb4066b6-75d3-45d0-f89d-b4540bbceb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['helmet', 'no_helmet']\n",
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 182MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Loss: 0.4959 - Val Acc: 76.47%\n",
            "Epoch [2/10] - Loss: 0.1538 - Val Acc: 80.59%\n",
            "Epoch [3/10] - Loss: 0.0402 - Val Acc: 78.82%\n",
            "Epoch [4/10] - Loss: 0.0163 - Val Acc: 77.65%\n",
            "Epoch [5/10] - Loss: 0.0101 - Val Acc: 82.35%\n",
            "Epoch [6/10] - Loss: 0.0105 - Val Acc: 77.06%\n",
            "Epoch [7/10] - Loss: 0.0065 - Val Acc: 77.65%\n",
            "Epoch [8/10] - Loss: 0.0054 - Val Acc: 78.24%\n",
            "Epoch [9/10] - Loss: 0.0033 - Val Acc: 79.41%\n",
            "Epoch [10/10] - Loss: 0.0043 - Val Acc: 80.00%\n",
            "Saved model to /content/resnet18_helmet_binary.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/resnet18_helmet_binary.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "osZ_HrrVnKbt",
        "outputId": "251f19ef-d875-4c1f-dfc4-664ede7141f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93ad66a3-1b97-41fc-89d4-12b350868b51\", \"resnet18_helmet_binary.pth\", 44791435)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}